{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><small><small>\n",
    "All the IPython Notebooks in **Clustering Algorithms** lecture series by **[Dr. Milaan Parmar](https://www.linkedin.com/in/milaanparmar/)** are available @ **[GitHub](https://github.com/milaan9/Clustering_Algorithms)**\n",
    "</i></small></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Cosine Transform\n",
    "This is a little jupyter notebook that does a discrete cosine transform (DCT). DCT is a thing like the Fourier transform that's used in JPGs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T05:47:41.351255Z",
     "start_time": "2021-11-21T05:47:36.999785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T06:15:12.098078Z",
     "start_time": "2021-11-21T06:15:12.024489Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import utils as util\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "\n",
    "def cnn_encoder_layer(data, filter_layer, strides):\n",
    "    \"\"\"\n",
    "    :param data: the input data, when it is the first layer is 5 * 30 * 30 * 3, the second layer is 30 * 30 * 32,\n",
    "                 the third layer is 15 * 15 * 64, the fourth layer is 8 * 8 * 128\n",
    "    :param filter_layer:\n",
    "    :param strides:\n",
    "    :return: the result after conv, the first layer is 30 * 30 * 32, the second layer is 15 * 15 * 64, the third layer\n",
    "             is 8 * 8 * 128, the final layer is 4 * 4 * 256\n",
    "    \"\"\"\n",
    "\n",
    "    result = tf.nn.conv2d(\n",
    "        input=data,\n",
    "        filter=filter_layer,\n",
    "        strides=strides,\n",
    "        padding=\"SAME\")\n",
    "    return tf.nn.selu(result)\n",
    "\n",
    "\n",
    "def tensor_variable(shape, name):\n",
    "    \"\"\"\n",
    "    Tensor variable declaration initialization\n",
    "    :param shape:\n",
    "    :param name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    variable = tf.Variable(tf.zeros(shape), name=name)\n",
    "    variable = tf.compat.v1.get_variable(name, shape=shape, initializer=tf.compat.v1.estimator.layers.xavier_initializer())\n",
    "    return variable\n",
    "\n",
    "\n",
    "def cnn_encoder(data):\n",
    "    \"\"\"\n",
    "\n",
    "    :param data: the input data size is 5 * 30 * 30 * 3\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # the first layer,the output size is 30 * 30 * 32\n",
    "    filter1 = tensor_variable([3, 3, 3, 32], \"filter1\")\n",
    "    strides1 = (1, 1, 1, 1)\n",
    "    cnn1_out = cnn_encoder_layer(data, filter1, strides1)\n",
    "\n",
    "    # the second layer, the output size is 15 * 15 * 64\n",
    "    filter2 = tensor_variable([3, 3, 32, 64], \"filter2\")\n",
    "    strides2 = (1, 2, 2, 1)\n",
    "    cnn2_out = cnn_encoder_layer(cnn1_out, filter2, strides2)\n",
    "\n",
    "    # the third layer, the output size is 8 * 8 * 128\n",
    "    filter3 = tensor_variable([2, 2, 64, 128], \"filter3\")\n",
    "    strides3 = (1, 2, 2, 1)\n",
    "    cnn3_out = cnn_encoder_layer(cnn2_out, filter3, strides3)\n",
    "\n",
    "    # the fourth layer, the output size is 4 * 4 * 256\n",
    "    filter4 = tensor_variable([2, 2, 128, 256], \"filter4\")\n",
    "    strides4 = (1, 2, 2, 1)\n",
    "    cnn4_out = cnn_encoder_layer(cnn3_out, filter4, strides4)\n",
    "\n",
    "    return cnn1_out, cnn2_out, cnn3_out, cnn4_out\n",
    "\n",
    "\n",
    "def cnn_lstm_attention_layer(input_data, layer_number):\n",
    "    \"\"\"\n",
    "\n",
    "    :param input_data:\n",
    "    :param layer_number:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    convlstm_layer = tf.contrib.rnn.ConvLSTMCell(\n",
    "        conv_ndims=2,\n",
    "        input_shape=[input_data.shape[2], input_data.shape[3], input_data.shape[4]],\n",
    "        output_channels=input_data.shape[-1],\n",
    "        kernel_shape=[2, 2],\n",
    "        use_bias=True,\n",
    "        skip_connection=False,\n",
    "        forget_bias=1.0,\n",
    "        initializers=None,\n",
    "        name=\"conv_lstm_cell\" + str(layer_number))\n",
    "\n",
    "    outputs, state = tf.nn.dynamic_rnn(convlstm_layer, input_data, dtype=input_data.dtype)\n",
    "\n",
    "    # attention based on inner-product between feature representation of last step and other steps\n",
    "    attention_w = []\n",
    "    for k in range(util.step_max):\n",
    "        attention_w.append(tf.reduce_sum(tf.multiply(outputs[0][k], outputs[0][-1])) / util.step_max)\n",
    "    attention_w = tf.reshape(tf.nn.softmax(tf.stack(attention_w)), [1, util.step_max])\n",
    "\n",
    "    outputs = tf.reshape(outputs[0], [util.step_max, -1])\n",
    "    outputs = tf.matmul(attention_w, outputs)\n",
    "    outputs = tf.reshape(outputs, [1, input_data.shape[2], input_data.shape[3], input_data.shape[4]])\n",
    "\n",
    "    return outputs, attention_w\n",
    "\n",
    "\n",
    "def cnn_decoder_layer(conv_lstm_out_c, filter, output_shape, strides):\n",
    "    \"\"\"\n",
    "\n",
    "    :param conv_lstm_out_c:\n",
    "    :param filter:\n",
    "    :param output_shape:\n",
    "    :param strides:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    deconv = tf.nn.conv2d_transpose(\n",
    "        value=conv_lstm_out_c,\n",
    "        filter=filter,\n",
    "        output_shape=output_shape,\n",
    "        strides=strides,\n",
    "        padding=\"SAME\")\n",
    "    deconv = tf.nn.selu(deconv)\n",
    "    return deconv\n",
    "\n",
    "\n",
    "def cnn_decoder(lstm1_out, lstm2_out, lstm3_out, lstm4_out):\n",
    "    d_filter4 = tensor_variable([2, 2, 128, 256], \"d_filter4\")\n",
    "    dec4 = cnn_decoder_layer(lstm4_out, d_filter4, [1, 8, 8, 128], (1, 2, 2, 1))\n",
    "    dec4_concat = tf.concat([dec4, lstm3_out], axis=3)\n",
    "\n",
    "    d_filter3 = tensor_variable([2, 2, 64, 256], \"d_filter3\")\n",
    "    dec3 = cnn_decoder_layer(dec4_concat, d_filter3, [1, 15, 15, 64], (1, 2, 2, 1))\n",
    "    dec3_concat = tf.concat([dec3, lstm2_out], axis=3)\n",
    "\n",
    "    d_filter2 = tensor_variable([3, 3, 32, 128], \"d_filter2\")\n",
    "    dec2 = cnn_decoder_layer(dec3_concat, d_filter2, [1, 30, 30, 32], (1, 2, 2, 1))\n",
    "    dec2_concat = tf.concat([dec2, lstm1_out], axis=3)\n",
    "\n",
    "    d_filter1 = tensor_variable([3, 3, 3, 64], \"d_filter1\")\n",
    "    dec1 = cnn_decoder_layer(dec2_concat, d_filter1, [1, 30, 30, 3], (1, 1, 1, 1))\n",
    "\n",
    "    return dec1\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Read dataset from file\n",
    "    matrix_data_path = util.train_data_path + \"train.npy\"\n",
    "    matrix_gt_1 = np.load(matrix_data_path)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    data_input = tf.compat.v1.placeholder(tf.float32, [util.step_max, 30, 30, 3])\n",
    "\n",
    "    # cnn encoder\n",
    "    conv1_out, conv2_out, conv3_out, conv4_out = cnn_encoder(data_input)\n",
    "\n",
    "    conv1_out = tf.reshape(conv1_out, [-1, 5, 30, 30, 32])\n",
    "    conv2_out = tf.reshape(conv2_out, [-1, 5, 15, 15, 64])\n",
    "    conv3_out = tf.reshape(conv3_out, [-1, 5, 8, 8, 128])\n",
    "    conv4_out = tf.reshape(conv4_out, [-1, 5, 4, 4, 256])\n",
    "\n",
    "    # lstm with attention\n",
    "    conv1_lstm_attention_out, atten_weight_1 = cnn_lstm_attention_layer(conv1_out, 1)\n",
    "    conv2_lstm_attention_out, atten_weight_2 = cnn_lstm_attention_layer(conv2_out, 2)\n",
    "    conv3_lstm_attention_out, atten_weight_3 = cnn_lstm_attention_layer(conv3_out, 3)\n",
    "    conv4_lstm_attention_out, atten_weight_4 = cnn_lstm_attention_layer(conv4_out, 4)\n",
    "\n",
    "    # cnn decoder\n",
    "    deconv_out = cnn_decoder(conv1_lstm_attention_out, conv2_lstm_attention_out, conv3_lstm_attention_out,\n",
    "                             conv4_lstm_attention_out)\n",
    "    # loss function: reconstruction error of last step matrix\n",
    "    loss = tf.reduce_mean(tf.square(data_input[-1] - deconv_out))\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=util.learning_rate).minimize(loss)\n",
    "\n",
    "    # variable initialization\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # training\n",
    "    for idx in range(util.train_start_id, util.train_end_id):\n",
    "        matrix_gt = matrix_gt_1[idx - util.train_start_id]\n",
    "        feed_dict = {data_input: np.asarray(matrix_gt)}\n",
    "        a, loss_value = sess.run([optimizer, loss], feed_dict)\n",
    "        print(\"mse of last train data: \" + str(loss_value))\n",
    "\n",
    "    # test\n",
    "    # Read the data from test file.\n",
    "    matrix_data_path = util.test_data_path + \"test.npy\"\n",
    "    matrix_gt_1 = np.load(matrix_data_path)\n",
    "    result_all = []\n",
    "    for idx in range(util.test_start_id, util.test_end_id):\n",
    "        matrix_gt = matrix_gt_1[idx - util.test_start_id]\n",
    "        feed_dict = {data_input: np.asarray(matrix_gt)}\n",
    "        result, loss_value = sess.run([deconv_out, loss], feed_dict)\n",
    "        result_all.append(result)\n",
    "        print(\"mse of last test data: \" + str(loss_value))\n",
    "\n",
    "    # Write the reconstructed matrix to the file\n",
    "    reconstructed_path = util.reconstructed_data_path\n",
    "    if not os.path.exists(reconstructed_path):\n",
    "        os.makedirs(reconstructed_path)\n",
    "    reconstructed_path = reconstructed_path + \"test_reconstructed.npy\"\n",
    "\n",
    "    result_all = np.asarray(result_all).reshape((-1, 30, 30, 3))\n",
    "    print(result_all.shape)\n",
    "    np.save(reconstructed_path, result_all)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
